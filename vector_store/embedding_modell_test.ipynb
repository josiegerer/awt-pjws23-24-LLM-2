{"cells":[{"cell_type":"markdown","metadata":{"id":"JyNfnCScexM5"},"source":["### Embedding Models\n"]},{"cell_type":"markdown","metadata":{"id":"cwa1IKZp0xxS"},"source":["To determine the most suitable embedding model for our use case, we evaluated the Sentence Transformers models all-mpnet-base-v2, all-MiniLM-L6-v2, and all-MiniLM-L12-v2. The <a href=https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2>all-MiniLM-L12-v2</a> model provided the best outcomes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14445,"status":"ok","timestamp":1707300846618,"user":{"displayName":"taniam0on","userId":"11642366558189184577"},"user_tz":-60},"id":"XN54mB46ZCtR","outputId":"621e1e2f-037e-482a-b529-b2da5a437a8a"},"outputs":[],"source":["#!pip install langchain sentence_transformers faiss-cpu pypdf InstructorEmbedding -U sentence-transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxAEE2BSZGuZ","outputId":"befdc1f8-e6aa-4acc-8110-ac162c51aa1c"},"outputs":[],"source":["#!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"]},{"cell_type":"markdown","metadata":{"id":"-rm5cgdjes7_"},"source":["### Setting Llama Modell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXnG5Tu5ZMQn"},"outputs":[],"source":["#!wget https://huggingface.co/TheBloke/Llama-2-7B-chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-57qJ0pZOX6"},"outputs":[],"source":["%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZXRRwNXZP3H"},"outputs":[],"source":["from langchain.chains import LLMChain\n","from langchain.embeddings import LlamaCppEmbeddings\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain.llms import LlamaCpp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1N2_LU_5Rt1"},"outputs":[],"source":["B_INST, E_INST = \"[INST]\", \"[/INST]\"\n","B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n","# DEFAULT_SYSTEM_PROMPT = \"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information\"\n","DEFAULT_SYSTEM_PROMPT = \"Answer the question by the document you have.\"\n","\n","SYSTEM_PROMPT = B_SYS + DEFAULT_SYSTEM_PROMPT +E_SYS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eMX67VW5SwY"},"outputs":[],"source":["def get_prompt(instruction):\n","    return B_INST + SYSTEM_PROMPT + instruction + E_INST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSuaZ5PD6W9L"},"outputs":[],"source":["from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9JY0rel6W9M"},"outputs":[],"source":["prompt_template = B_INST +SYSTEM_PROMPT + \"{user_message}\" + E_INST\n","prompt_template"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWy1_C8uZRbj"},"outputs":[],"source":["n_batch = 512\n","n_gpu_layers = 1\n","callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n","\n","# Alternative: llama = LlamaCppEmbeddings\n","llama = LlamaCpp(model_path=\"llama-2-7b-chat.Q4_K_M.gguf\",\n","                           n_batch = n_batch,\n","                           n_gpu_layers = n_gpu_layers,\n","                           n_ctx=4096,\n","                           f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n","                           callback_manager=callback_manager,\n","                           verbose=True,\n","                           )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4oeOp5B5W8d"},"outputs":[],"source":["llm_chain = LLMChain(llm=llama, prompt=PromptTemplate.from_template(prompt_template))  "]},{"cell_type":"markdown","metadata":{"id":"iCwkqpORe-Yb"},"source":["### Faiss with Retriever"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"geQZ0kdwdlCs"},"outputs":[],"source":["from langchain.vectorstores import FAISS\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","from langchain.chains import RetrievalQA\n","from langchain.document_loaders import TextLoader\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.document_loaders import DirectoryLoader\n","\n","\n","from InstructorEmbedding import INSTRUCTOR\n","from langchain.embeddings import HuggingFaceInstructEmbeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPcM7GvHfo8A"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsU6ksj0fwFB"},"outputs":[],"source":["# loader = TextLoader('.txt')\n","loader = DirectoryLoader(f'{root_dir}/Documents/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n","documents = loader.load()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0ren1Ouf4np"},"outputs":[],"source":["len(documents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZfWNAmdf8NL"},"outputs":[],"source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","chunked_data = text_splitter.split_documents(documents)"]},{"cell_type":"markdown","metadata":{"id":"mRdCo0ivgC2n"},"source":["### HuggingFace Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAFagmfUgQhF"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","from langchain.embeddings import HuggingFaceEmbeddings\n","sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n","\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n","embeddings = model.encode(sentences)\n","#print(embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgsxacJXhPV1"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","embedding_model = HuggingFaceEmbeddings(\n","        model_name=\"sentence-transformers/all-MiniLM-L12-v2\",\n","        model_kwargs={\"device\": \"cuda\"},) # cpu lokal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVrG-KJO6W9Q"},"outputs":[],"source":["from langchain.embeddings import HuggingFaceInstructEmbeddings\n","embedding_function = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\",\n","                                                      model_kwargs={\"device\": \"cuda\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKudmVKgrs70"},"outputs":[],"source":["db = FAISS.from_documents(chunked_data, embedding_function)\n","\n","query = \"How many Use Case are there?\"\n","docs = db.similarity_search(query)\n","\n","print(docs[0].page_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8uDIKqjwoFf"},"outputs":[],"source":["retriever = db.as_retriever(search_kwargs={\"k\": 3})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEybhdo1xJSQ"},"outputs":[],"source":["qa_chain = RetrievalQA.from_chain_type(llama,\n","                                  chain_type=\"stuff\",\n","                                  retriever=retriever,\n","                                  return_source_documents=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPZPGSW2xJZA"},"outputs":[],"source":["import textwrap\n","\n","def wrap_text_preserve_newlines(text, width=110):\n","    lines = text.split('\\n')\n","    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n","    wrapped_text = '\\n'.join(wrapped_lines)\n","\n","    return wrapped_text\n","\n","def process_llm_response(llm_response):\n","    print(wrap_text_preserve_newlines(llm_response['result']))\n","    print('\\n\\nSources:')\n","    for source in llm_response[\"source_documents\"]:\n","        print(source.metadata['source'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhCWgI6pBFMv"},"outputs":[],"source":["query = \"What is the project about?\"\n","llm_response = qa_chain(query)\n","print(\"/\")\n","process_llm_response(llm_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUFmFCFBBTu7"},"outputs":[],"source":["query = \"How many use cases are mentioned?\"\n","llm_response = qa_chain(query)\n","print(\" / \")\n","process_llm_response(llm_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NETpvcWzbM_4"},"outputs":[],"source":["# Mit Callbackmanager\n","query = \"When is the deadline for the video?\"\n","llm_response = qa_chain(query)\n","print(\" / \")\n","process_llm_response(llm_response)"]},{"cell_type":"markdown","metadata":{"id":"Afw-K8e1dJNW"},"source":["### Retriever"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLVLoXk6BWbz"},"outputs":[],"source":["qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHApPP2sBXwb"},"outputs":[],"source":["print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xq2a-mmdCjE"},"outputs":[],"source":["from langchain.chains import ConversationalRetrievalChain\n","\n","chain = ConversationalRetrievalChain.from_llm(llama, db.as_retriever(), return_source_documents=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxvQe_8OdPyM"},"outputs":[],"source":["chat_history = []\n","\n","query = \"How many Uses Cases are in the project mentioned?\"\n","result = chain({\"question\": query, \"chat_history\": chat_history})\n","\n","print(result['answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXgKmoa9dT--"},"outputs":[],"source":["chat_history = [(query, result[\"answer\"])]\n","\n","query = \"What is the project about?\"\n","result = chain({\"question\": query, \"chat_history\": chat_history})\n","\n","print(result['answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lg2TYuOUdb4t"},"outputs":[],"source":["print(result['source_documents'])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
